{
    "report_to": "wandb",
    "run_name": "run10-bert-squad-hybrid",
    "ampere_pruning_method": "disabled",
    "attention_block_cols": 32,
    "attention_block_rows": 32,
    "attention_lambda": 1.0,
    "attention_output_with_dense": 0,
    "attention_pruning_method": "sigmoied_threshold",
    "dataset_name": "squad",
    "dense_block_cols": 1,
    "dense_block_rows": 1,
    "dense_lambda": 1.0,
    "dense_pruning_method": "sigmoied_threshold:1d_alt",
    "distil_alpha_ce": 0.1,
    "distil_alpha_teacher": 0.9,
    "distil_teacher_name_or_path": "bert-large-uncased-whole-word-masking-finetuned-squad",
    "do_eval": 1,
    "do_train": 1,
    "doc_stride": 128,
    "eval_steps": 250,
    "eval_with_current_patch_params ": 0,
    "evaluation_strategy": "steps",
    "final_threshold": 0.1,
    "final_warmup": 10,
    "gelu_patch": false,
    "gelu_patch_steps": 50000,
    "initial_threshold": 0,
    "initial_warmup": 1,
    "layer_norm_patch": false,
    "layer_norm_patch_steps": 50000,
    "learning_rate": 3e-05,
    "linear_min_parameters": 0,
    "logging_steps": 1,
    "mask_init": "constant",
    "mask_scale": 0.0,
    "mask_scores_learning_rate": 0.01,
    "max_seq_length": 384,
    "model_name_or_path": "bert-base-uncased",
    "null_score_diff_threshold": 0.0,
    "num_train_epochs": 20,
    "overwrite_cache": 0,
    "overwrite_output_dir": 1,
    "per_device_eval_batch_size": 128,
    "per_device_train_batch_size": 16,
    "qat": false,
    "qconfig": "default",
    "regularization": "l1",
    "regularization_final_lambda": 20.0,
    "save_steps": 5000,
    "save_total_limit": 10,
    "seed": 17,
    "version_2_with_negative": 0,
    "warmup_steps": 5400
}
